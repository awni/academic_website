<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="maintained-by" content="Awni Hannun">
    <meta name="author" content="Awni Hannun">
    <meta name="keywords" content="Awni Hannun">

    <!-- Favicon -->
    <link rel="apple-touch-icon" sizes="180x180" href="assets/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="assets/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="assets/favicon-16x16.png">
    <link rel="manifest" href="assets/site.webmanifest">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link href="assets/styles.css" rel="stylesheet">

    <title>Awni Hannun</title>
    <style>
    </style>
  </head>

  <body>
    <div class="container mt-5 mb-5">
      <div class="row">
        <div class="col">
          <h2>Awni Hannun</a></h2>
          <hr>
        </div>
      </div>
      <div class="row pt-md-5">
        <div class="col-md-2 mb-2">
          <nav class="nav flex-column nav-pills">
            <a class="nav-item nav-link" href="./index.html">Home</a>
            <a class="nav-item nav-link" href="./research.html">Research</a>
            <a class="nav-item nav-link active" href="./publications.html">Publications</a>
            <a class="nav-item nav-link" href="./software.html">Software</a>
            <a class="nav-item nav-link" href="./misc.html">Misc</a>
          </nav>
        </div>

        <div class="col-md-8">
          <main class="shadow p-3 mb-5 bg-white rounded" style="padding:10px">

<div id="papers">
<h3>Publications and Preprints</h3>

<ul>
  <li><strong>Transcribing Real-valued Sequences with Deep Neural Networks.</strong>
  Awni Y. Hannun.  PhD Thesis, Stanford University, 2018. (<a href="https://stacks.stanford.edu/file/druid:ft390rb7614/thesis-augmented.pdf">pdf</a>)
  </li>

  <li><strong>Sequence Modeling With CTC.</strong>
  Awni Y. Hannun.  Distill, 2017. (<a href="https://distill.pub/2017/ctc/">html</a>)
  </li>

  <li><strong>Cardiologist-Level Arrhythmia Detection with Convolutional Neural Networks.</strong>
  Pranav Rajpurkar*, Awni Y. Hannun*, Masoumeh Haghpanahi, Codie Bourn and Andrew Y. Ng.
  arXiv:1707.01836, 2017. (<a href="https://arxiv.org/pdf/1707.01836">pdf</a>,
  <a href="https://stanfordmlgroup.github.io/projects/ecg/">web page</a>)
  <br />
  Mentions: <a href="https://www.technologyreview.com/s/608234/the-machines-are-getting-ready-to-play-doctor/">MIT Tech Review</a>,
  <a href="http://news.stanford.edu/2017/07/06/algorithm-diagnoses-heart-arrhythmias-cardiologist-level-accuracy/">Stanford News</a>
  </li>

  <li><strong>Building DNN Acoustic Models for Large Vocabulary Speech Recognition.</strong>
  Andrew L. Maas, Peng Qi, Ziang Xie, Awni Y. Hannun, Christopher T. Lengerich,
  Daniel Jurafsky and Andrew Y. Ng. (2017). Computer Speech &amp; Language, Volume 41, Pages 195-213.
  (<a href="http://www.sciencedirect.com/science/article/pii/S0885230816301930">link</a>)
  </li>

  <li><strong>An End-to-End Architecture for Keyword Spotting and Voice
  Activity Detection,</strong> Chris Lengerich* and Awni Hannun*. In NIPS 2016
  Workshop on End-to-End Learning for Speech and Audio Processing.
  (<a href="https://arxiv.org/pdf/1611.09405.pdf">pdf</a>,
  <a href="https://github.com/mindorii/kws">code</a>)
  </li>

  <li><strong>Persistent RNNs: Stashing Recurrent Weights On-Chip,</strong>
  Gregory Diamos, Shubho Sengupta, Bryan Catanzaro, Mike Chrzanowski,
  Adam Coates, Erich Elsen, Jesse Engel, Awni Hannun, Sanjeev Satheesh.
  In ICML 2016. 
  (<a href="http://jmlr.org/proceedings/papers/v48/diamos16.pdf">pdf</a>)
  </li>

  <li><strong>Deep Speech 2: End-to-End Speech Recognition in English and Mandarin,</strong>
  <a href="http://research.baidu.com/silicon-valley-ai-lab/" target="_blank">SVAIL</a>. In ICML 2016. 
  (<a href="http://jmlr.org/proceedings/papers/v48/amodei16.pdf">pdf</a>, <a href="http://arxiv.org/pdf/1512.02595.pdf">long</a>)
  <br />
  Mentions: <a href="https://www.technologyreview.com/s/600766/conversational-interfaces/" target="_blank">MIT Tech Review</a>,
  <a href="https://www.technologyreview.com/s/544651/baidus-deep-learning-system-rivals-people-at-speech-recognition/" target="_blank">MIT Tech Review</a>
  </li>

  <li><strong>Lookahead Convolution Layer for Unidirectional Recurrent Neural Networks,</strong>
  Chong Wang*, Dani Yogatama*, Adam Coates, Tony Han, Awni Hannun, and Bo Xiao.
  ICLR Workshop, 2016. 
  (<a href="http://www.cs.cmu.edu/~dyogatam/papers/wang+etal.iclrworkshop2016.pdf">pdf</a>)
  </li>

  <li><strong>Learning Multiscale Features Directly From Waveforms,</strong>
  Zhenyao Zhu, Jesse H. Engel, Awni Hannun.
  Interspeech, 2016.
  (<a href="http://arxiv.org/pdf/1603.09509.pdf">pdf</a>)
  </li>

  <li><strong>Deep Speech: Scaling up end-to-end speech recognition,</strong>
  Awni Y. Hannun, Carl Case, Jared Casper, Bryan Catanzaro, Greg Diamos, Erich
  Elsen, Ryan Prenger, Sanjeev Satheesh, Shubho Sengupta, Adam Coates, Andrew
  Y. Ng. arXiv:1412.5567, 2014. 
  (<a href="http://arxiv.org/pdf/1412.5567.pdf">pdf</a>)
  <br />
  Mentions: <a href="http://www.forbes.com/sites/roberthof/2014/12/18/baidu-announces-breakthrough-in-speech-recognition-claiming-to-top-google-and-apple/#6a9652845a11" target="_blank">Forbes</a>
  </li>

  <li><strong>First-Pass Large Vocabulary Continuous Speech Recognition using
  Bi-Directional Recurrent DNNs,</strong> Awni Y. Hannun, Andrew L. Maas,
  Daniel Jurafsky and Andrew Y. Ng. arXiv:1408.2873, 2014. (<a
  href="http://arxiv.org/pdf/1408.2873.pdf">pdf</a>,
  <a href=https://gist.github.com/awni/56369a90d03953e370f3964c826ed4b0>example decoder</a>)</li>

  <li><strong>Increasing Deep Neural Network Acoustic Model Size for Large
    Vocabulary Continuous Speech Recognition,</strong> Andrew L. Maas, Awni Y.
  Hannun, Christopher T. Lengerich, Peng Qi, Daniel Jurafsky and Andrew Y. Ng.
  arXiv:1406.7806, 2014. (<a href="http://arxiv.org/pdf/1406.7806.pdf">pdf</a>)</li>

	<li><strong>Rectifier Nonlinearities Improve Neural Network
	Acoustic Models,</strong> Andrew L. Maas, Awni Y. Hannun, and Andrew
	Y. Ng. ICML Workshop on Deep Learning for Audio, Speech,
	and Language Processing (WDLASL 2013). (<a href="papers/relu_hybrid_icml2013_final.pdf">pdf</a>)</li>
	<li><strong>Recurrent Neural Network Feature Enhancement: The 2nd
	Chime Challenge,</strong> Andrew L. Maas, Tyler M. O'Neil, Awni
	Y. Hannun, Andrew Y. Ng. The 2nd International Workshop on Machine
	Listening in Multisource Environments (CHiME 2013). (<a href="papers/drdae_chime2013_final.pdf">pdf</a>)</li>

</div>

          </main>
        </div>
      </div>
    </div>
  </body>
</html>
